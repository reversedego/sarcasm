{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions of helper function\n",
    "\n",
    "class MySQLConnection:\n",
    "    def __init__(self,user,hostname,db,):\n",
    "        self.user = str(user)\n",
    "        self.hostname = str(hostname)\n",
    "        self.db = str(db)\n",
    "        pword = getpass.getpass(\"Enter password for user {}\".format(user))\n",
    "        self.engine = create_engine(\"mysql://{}:{}@{}/{}\".format(user,pword,hostname,db))\n",
    "        # Writing logic in ObjectLogic.py depends on this being named cnx:\n",
    "        self.cnx = self.engine.connect()\n",
    "    \n",
    "    def write_to_db(self, df, table_name):\n",
    "        try:\n",
    "            df.to_sql(table_name,con = self.cnx,if_exists='append',index=False)\n",
    "        except Exception as e:\n",
    "            print(\"\\n SQL Write error with: \")\n",
    "            print(df,\"\\n\", e)\n",
    "    \n",
    "    def get_table(self,table_name):\n",
    "        q1 = \"SELECT * FROM \"\n",
    "        query = q1 + table_name\n",
    "        return pd.read_sql(query,self.cnx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sql connection\n",
    "sql = MySQLConnection('skrs','localhost','sarcasm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_set = train_data.dropna() # Drop any rows with anything missing. Not too many of them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, put the dataset into an SQL database for getting general insights\n",
    "# # train_data.to_sql('initial_data',sql.cnx) # needs to be executed once  -  DONE\n",
    "\n",
    "\n",
    "# Certain subreddits are more likely to have sarcastic comments.\n",
    "# Idea: Get the correlation between subreddit and sarcasm. Can be used to weigh results and/or as an additiona validation\n",
    "# Easy enough to do with MySQL\n",
    "\n",
    "\n",
    "# Assign to subreddits how many comments they have\n",
    "\"\"\"\n",
    "create table data_subr_counts as \n",
    "select \n",
    "    subreddit as sub, \n",
    "    count(*) as entry_count\n",
    "from \n",
    "    test_data\n",
    "group by subreddit\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Leave only the subreddits with comment count > 30 \n",
    "# (more or less arbitrarily chosen amount but should make the results more statistically significant)\n",
    "\"\"\"\n",
    "create table test_data_relev as \n",
    "select * \n",
    "from \n",
    "    test_data left join data_subr_counts \n",
    "        on test_data.subreddit = data_subr_counts.sub\n",
    "where entry_count > 30\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Now count how many sarcastic comments and how many non-sarcastic comments are in each subreddit \n",
    "\"\"\"\n",
    "create table relevant_nonsarcastic_comment_counts\n",
    "as select \n",
    "    subreddit, \n",
    "    count(*) as nonsarc_count \n",
    "from \n",
    "    test_data_relev \n",
    "where \n",
    "    label = 0 \n",
    "group by \n",
    "    subreddit\n",
    "\"\"\"\n",
    "\"\"\"    \n",
    "\n",
    "create table relevant_sarcastic_comment_counts\n",
    "as select \n",
    "    subreddit as sub, \n",
    "    count(*) as sarc_count \n",
    "from \n",
    "    test_data_relev \n",
    "where \n",
    "    label = 1 \n",
    "group by \n",
    "    subreddit\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#And finally calculate the sarcasm ratio for each (definitely) statistically relevant sub\n",
    "\"\"\"\n",
    "create table relevant_sarcasm_ratio \n",
    "as select \n",
    "    subreddit,\n",
    "    sarc_count / (nonsarc_count + sarc_count) as sarcasm_ratio\n",
    "from \n",
    "    relevant_sarcastic_comment_counts join relevant_nonsarcastic_comment_counts\n",
    "        on relevant_sarcastic_comment_counts.sub = relevant_nonsarcastic_comment_counts.subreddit\n",
    "\"\"\"\n",
    "\n",
    "# subr_sarcasm_ratio = sql.get_table('relevant_sarcasm_ratio')\n",
    "# subr_sarcasm_ratio\n",
    "\n",
    "# Question: \n",
    "# How was the data collected? Was it equal amounts of sarcastic and non-sarcastic comments from each subreddit?\n",
    "\n",
    "\n",
    "# Idea: Amount of sarcasm in comments varies based on the day of the week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate token_pattern='[a-z]{2,}'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is the basic version  of the model\n",
    "\"\"\"\n",
    "\n",
    "vect = CountVectorizer(min_df=5)\n",
    "vect.fit(test_set['comment'])\n",
    "\n",
    "X_tr, X_tst, y_train, y_test = train_test_split(test_set['comment'],test_set['label'])\n",
    "\n",
    "X_train = vect.transform(X_tr)\n",
    "X_test = vect.transform(X_tst)\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[::2000])\n",
    "print(len(feature_names))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# # Basic version.\n",
    "# # Some misspellings can be frequent and should correlate with sarcasm about the same as the correct versions of the words but\n",
    "# rarer misspellings just bloat the number of features, same with rare words that wont be statistically significant.\n",
    "# # Conclusion: \n",
    "# Ignore words with less than 5 occurences: mind_df = 5\n",
    "# ngram size = 1 (default)\n",
    "# nothing else is taken into consideration besides the comment itself\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basic + 1-2-gramms \n",
    "# vect = CountVectorizer(min_df=5,ngram_range=(1,2))\n",
    "# vect.fit(test_set['comment'])\n",
    "# score:  0.718619325052215\n",
    "# (682272, 215441)\n",
    "# score:  0.7181444432230406\n",
    "# (682272, 215441)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basic + 1-3-gramms \n",
    "# vect = CountVectorizer(min_df=5,ngram_range=(1,3))\n",
    "# vect.fit(test_set['comment'])\n",
    "# score:  0.7199604265142354\n",
    "# (682272, 342466)\n",
    "# score:  0.7205979993404419\n",
    "# (682272, 342466)\n",
    "\n",
    "\n",
    "# Basic 2-3-gramms\n",
    "# vect = CountVectorizer(min_df=5,ngram_range=(2,3))\n",
    "# vect.fit(test_set['comment'])\n",
    "# score:  0.695776629658129\n",
    "# (682272, 302974)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Model with the subreddit added as an additional word\n",
    "\"\"\"\n",
    "\n",
    "test_set['empty_str'] = \" \" # Ignoring SettingWithCopyWarning. Value =/= f(index). Just need the right shape\n",
    "vect = TfidfVectorizer(min_df=5,ngram_range=(1,2))\n",
    "new_set = pd.DataFrame(test_set.comment + test_set.empty_str + test_set.subreddit)\n",
    "vect.fit(new_set[0]) # note the 'new_set' instead of test_set['comment']\n",
    "\n",
    "\n",
    "X_tr, X_tst, y_train, y_test = train_test_split(new_set[0],test_set['label']) # new_set[0] here as well\n",
    "\n",
    "X_train = vect.transform(X_tr)\n",
    "X_test = vect.transform(X_tst)\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[::2000])\n",
    "print(len(feature_names))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"score: \", score)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Basic + Add subreddit to the features. \n",
    "# https://www.dataquest.io/blog/settingwithcopywarning/\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "# score:  0.6975882158953501\n",
    "# (682272, 43217)\n",
    "\n",
    "\n",
    "# Basic + Add subreddit to the features + 1-2 gramms \n",
    "# score:  0.7247883917775091\n",
    "# (682272, 242406)\n",
    "\n",
    "\n",
    "# Basic + add subreddit + 1-3 gramms \n",
    "# score:  0.7243354952182038\n",
    "# (682272, 374868)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
